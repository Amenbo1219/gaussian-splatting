{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d148ab-a5bc-43dd-902b-acfc1cf24d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (C) 2023, Inria\n",
    "# GRAPHDECO research group, https://team.inria.fr/graphdeco\n",
    "# All rights reserved.\n",
    "#\n",
    "# This software is free for non-commercial, research and evaluation use \n",
    "# under the terms of the LICENSE.md file.\n",
    "#\n",
    "# For inquiries contact  george.drettakis@inria.fr\n",
    "#\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from random import randint\n",
    "from utils.loss_utils import l1_loss, ssim\n",
    "from gaussian_renderer import render, network_gui\n",
    "import sys\n",
    "from scene import Scene, GaussianModel\n",
    "from utils.general_utils import safe_state\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from utils.image_utils import psnr\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    TENSORBOARD_FOUND = True\n",
    "except ImportError:\n",
    "    TENSORBOARD_FOUND = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8bbdd-e352-4968-8289-f13e8a4b9bb4",
   "metadata": {},
   "source": [
    "# Train(学習)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2a8255-9b0c-452e-9976-ff1f9ae357a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_output_and_logger(args):    \n",
    "    if not args.model_path:\n",
    "        if os.getenv('OAR_JOB_ID'):\n",
    "            unique_str=os.getenv('OAR_JOB_ID')\n",
    "        else:\n",
    "            unique_str = str(uuid.uuid4())\n",
    "        args.model_path = os.path.join(\"./output/\", unique_str[0:10])\n",
    "        \n",
    "    # Set up output folder\n",
    "    print(\"Output folder: {}\".format(args.model_path))\n",
    "    os.makedirs(args.model_path, exist_ok = True)\n",
    "    with open(os.path.join(args.model_path, \"cfg_args\"), 'w') as cfg_log_f:\n",
    "        cfg_log_f.write(str(Namespace(**vars(args))))\n",
    "\n",
    "    # Create Tensorboard writer\n",
    "    tb_writer = None\n",
    "    if TENSORBOARD_FOUND:\n",
    "        tb_writer = SummaryWriter(args.model_path)\n",
    "    else:\n",
    "        print(\"Tensorboard not available: not logging progress\")\n",
    "    return tb_writer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad123af-530a-485b-9a35-1018d33a9ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, checkpoint, debug_from):\n",
    "    first_iter = 0\n",
    "    tb_writer = prepare_output_and_logger(dataset)\n",
    "    print(dataset)\n",
    "    gaussians = GaussianModel(dataset.sh_degree)\n",
    "    scene = Scene(dataset, gaussians)\n",
    "    gaussians.training_setup(opt)\n",
    "    if checkpoint:\n",
    "        (model_params, first_iter) = torch.load(checkpoint)\n",
    "        gaussians.restore(model_params, opt)\n",
    "\n",
    "    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]\n",
    "    background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    iter_start = torch.cuda.Event(enable_timing = True)\n",
    "    iter_end = torch.cuda.Event(enable_timing = True)\n",
    "\n",
    "    viewpoint_stack = None\n",
    "    ema_loss_for_log = 0.0\n",
    "    progress_bar = tqdm(range(first_iter, opt.iterations), desc=\"Training progress\")\n",
    "    first_iter += 1\n",
    "    for iteration in range(first_iter, opt.iterations + 1):        \n",
    "        if network_gui.conn == None:\n",
    "            network_gui.try_connect()\n",
    "        while network_gui.conn != None:\n",
    "            try:\n",
    "                net_image_bytes = None\n",
    "                custom_cam, do_training, pipe.convert_SHs_python, pipe.compute_cov3D_python, keep_alive, scaling_modifer = network_gui.receive()\n",
    "                if custom_cam != None:\n",
    "                    net_image = render(custom_cam, gaussians, pipe, background, scaling_modifer)[\"render\"]\n",
    "                    net_image_bytes = memoryview((torch.clamp(net_image, min=0, max=1.0) * 255).byte().permute(1, 2, 0).contiguous().cpu().numpy())\n",
    "                network_gui.send(net_image_bytes, dataset.source_path)\n",
    "                if do_training and ((iteration < int(opt.iterations)) or not keep_alive):\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                network_gui.conn = None\n",
    "\n",
    "        iter_start.record()\n",
    "\n",
    "        gaussians.update_learning_rate(iteration)\n",
    "\n",
    "        # Every 1000 its we increase the levels of SH up to a maximum degree\n",
    "        if iteration % 1000 == 0:\n",
    "            gaussians.oneupSHdegree()\n",
    "\n",
    "        # Pick a random Camera\n",
    "        if not viewpoint_stack:\n",
    "            viewpoint_stack = scene.getTrainCameras().copy()\n",
    "        viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1))\n",
    "\n",
    "        # Render\n",
    "        if (iteration - 1) == debug_from:\n",
    "            pipe.debug = True\n",
    "\n",
    "        bg = torch.rand((3), device=\"cuda\") if opt.random_background else background\n",
    "\n",
    "        render_pkg = render(viewpoint_cam, gaussians, pipe, bg)\n",
    "        image, viewspace_point_tensor, visibility_filter, radii = render_pkg[\"render\"], render_pkg[\"viewspace_points\"], render_pkg[\"visibility_filter\"], render_pkg[\"radii\"]\n",
    "\n",
    "        # Loss\n",
    "        gt_image = viewpoint_cam.original_image.cuda()\n",
    "        Ll1 = l1_loss(image, gt_image)\n",
    "        loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image))\n",
    "        loss.backward()\n",
    "\n",
    "        iter_end.record()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Progress bar\n",
    "            ema_loss_for_log = 0.4 * loss.item() + 0.6 * ema_loss_for_log\n",
    "            if iteration % 10 == 0:\n",
    "                progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\"})\n",
    "                progress_bar.update(10)\n",
    "            if iteration == opt.iterations:\n",
    "                progress_bar.close()\n",
    "\n",
    "            # Log and save\n",
    "            training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end), testing_iterations, scene, render, (pipe, background))\n",
    "            if (iteration in saving_iterations):\n",
    "                print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "                scene.save(iteration)\n",
    "\n",
    "            # Densification\n",
    "            if iteration < opt.densify_until_iter:\n",
    "                # Keep track of max radii in image-space for pruning\n",
    "                gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "                gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)\n",
    "\n",
    "                if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:\n",
    "                    size_threshold = 20 if iteration > opt.opacity_reset_interval else None\n",
    "                    gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold)\n",
    "                \n",
    "                if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter):\n",
    "                    gaussians.reset_opacity()\n",
    "\n",
    "            # Optimizer step\n",
    "            if iteration < opt.iterations:\n",
    "                gaussians.optimizer.step()\n",
    "                gaussians.optimizer.zero_grad(set_to_none = True)\n",
    "\n",
    "            if (iteration in checkpoint_iterations):\n",
    "                print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "                torch.save((gaussians.capture(), iteration), scene.model_path + \"/chkpnt\" + str(iteration) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4fa7aa-b77b-496b-a81e-9c86bdb7e057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_report(tb_writer, iteration, Ll1, loss, l1_loss, elapsed, testing_iterations, scene : Scene, renderFunc, renderArgs):\n",
    "    if tb_writer:\n",
    "        tb_writer.add_scalar('train_loss_patches/l1_loss', Ll1.item(), iteration)\n",
    "        tb_writer.add_scalar('train_loss_patches/total_loss', loss.item(), iteration)\n",
    "        tb_writer.add_scalar('iter_time', elapsed, iteration)\n",
    "\n",
    "    # Report test and samples of training set\n",
    "    if iteration in testing_iterations:\n",
    "        torch.cuda.empty_cache()\n",
    "        validation_configs = ({'name': 'test', 'cameras' : scene.getTestCameras()}, \n",
    "                              {'name': 'train', 'cameras' : [scene.getTrainCameras()[idx % len(scene.getTrainCameras())] for idx in range(5, 30, 5)]})\n",
    "\n",
    "        for config in validation_configs:\n",
    "            if config['cameras'] and len(config['cameras']) > 0:\n",
    "                l1_test = 0.0\n",
    "                psnr_test = 0.0\n",
    "                for idx, viewpoint in enumerate(config['cameras']):\n",
    "                    image = torch.clamp(renderFunc(viewpoint, scene.gaussians, *renderArgs)[\"render\"], 0.0, 1.0)\n",
    "                    gt_image = torch.clamp(viewpoint.original_image.to(\"cuda\"), 0.0, 1.0)\n",
    "                    if tb_writer and (idx < 5):\n",
    "                        tb_writer.add_images(config['name'] + \"_view_{}/render\".format(viewpoint.image_name), image[None], global_step=iteration)\n",
    "                        if iteration == testing_iterations[0]:\n",
    "                            tb_writer.add_images(config['name'] + \"_view_{}/ground_truth\".format(viewpoint.image_name), gt_image[None], global_step=iteration)\n",
    "                    l1_test += l1_loss(image, gt_image).mean().double()\n",
    "                    psnr_test += psnr(image, gt_image).mean().double()\n",
    "                psnr_test /= len(config['cameras'])\n",
    "                l1_test /= len(config['cameras'])          \n",
    "                print(\"\\n[ITER {}] Evaluating {}: L1 {} PSNR {}\".format(iteration, config['name'], l1_test, psnr_test))\n",
    "                if tb_writer:\n",
    "                    tb_writer.add_scalar(config['name'] + '/loss_viewpoint - l1_loss', l1_test, iteration)\n",
    "                    tb_writer.add_scalar(config['name'] + '/loss_viewpoint - psnr', psnr_test, iteration)\n",
    "\n",
    "        if tb_writer:\n",
    "            tb_writer.add_histogram(\"scene/opacity_histogram\", scene.gaussians.get_opacity, iteration)\n",
    "            tb_writer.add_scalar('total_points', scene.gaussians.get_xyz.shape[0], iteration)\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ac28cc-faa1-432f-9fdf-3434d511d68a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   1%|▎                                         | 240/30000 [00:37<1:11:40,  6.92it/s, Loss=0.0617657]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Start GUI server, configure and run training\u001b[39;00m\n\u001b[1;32m     38\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(args\u001b[38;5;241m.\u001b[39mdetect_anomaly)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug_from\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# All done\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 70\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, checkpoint, debug_from)\u001b[0m\n\u001b[1;32m     66\u001b[0m iter_end\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Progress bar\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     ema_loss_for_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.6\u001b[39m \u001b[38;5;241m*\u001b[39m ema_loss_for_log\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     72\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mema_loss_for_log\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m7\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set up command line argument parser\n",
    "    parser = ArgumentParser(description=\"Training script parameters\",conflict_handler='resolve')\n",
    "    \n",
    "    lp = ModelParams(parser)\n",
    "\n",
    "    print(lp._model_path)\n",
    "    op = OptimizationParams(parser)\n",
    "    pp = PipelineParams(parser)\n",
    "    # parser.add_argument('-s', '--source_path', type=str, default=,\n",
    "    #                     help=\"Path to the source data\")\n",
    "    # parser.add_argument('-m', '--model_path', type=str, default='headphone',\n",
    "    #                     help=\"Path to save the model\")\n",
    "    \n",
    "    parser.add_argument('--ip', type=str, default=\"127.0.0.1\")\n",
    "    parser.add_argument('--port', type=int, default=6009)\n",
    "    parser.add_argument('--debug_from', type=int, default=-1)\n",
    "    parser.add_argument('--detect_anomaly', action='store_true', default=False)\n",
    "    parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "    parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "    parser.add_argument(\"--quiet\", action=\"store_true\")\n",
    "    parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=[])\n",
    "    parser.add_argument(\"--start_checkpoint\", type=str, default = None)\n",
    "    parser.add_argument(\"-f\", type=str, default = None)\n",
    "    \n",
    "    # args = parser.parse_args(sys.argv[1:])\n",
    "    args = parser.parse_args()\n",
    "    args.save_iterations.append(args.iterations)\n",
    "    args.source_path = \"/work/data/headphone/\" # \n",
    "    args.model_path = \"output/headphone\"\n",
    "    \n",
    "    print(\"Optimizing \" + args.model_path)\n",
    "\n",
    "    # Initialize system state (RNG)\n",
    "    safe_state(args.quiet)\n",
    "\n",
    "    # Start GUI server, configure and run training\n",
    "    torch.autograd.set_detect_anomaly(args.detect_anomaly)\n",
    "    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)\n",
    "\n",
    "    # All done\n",
    "    print(\"\\nTraining complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c845a-abd6-4a5c-9f9b-e8c70dad100d",
   "metadata": {},
   "source": [
    "# Rendering(今回は使わない．評価実験のときに使う)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99a98a4-b7dc-4419-8a45-e68cfc47351d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from scene import Scene\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from os import makedirs\n",
    "# from gaussian_renderer import render\n",
    "# import torchvision\n",
    "# from utils.general_utils import safe_state\n",
    "# from argparse import ArgumentParser\n",
    "# from arguments import ModelParams, PipelineParams, get_combined_args\n",
    "# from gaussian_renderer import GaussianModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4cfb80-5f64-49bc-ad4a-5267ae527692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def render_set(model_path, name, iteration, views, gaussians, pipeline, background):\n",
    "#     render_path = os.path.join(model_path, name, \"ours_{}\".format(iteration), \"renders\")\n",
    "#     gts_path = os.path.join(model_path, name, \"ours_{}\".format(iteration), \"gt\")\n",
    "\n",
    "#     makedirs(render_path, exist_ok=True)\n",
    "#     makedirs(gts_path, exist_ok=True)\n",
    "\n",
    "#     for idx, view in enumerate(tqdm(views, desc=\"Rendering progress\")):\n",
    "#         rendering = render(view, gaussians, pipeline, background)[\"render\"]\n",
    "#         gt = view.original_image[0:3, :, :]\n",
    "#         torchvision.utils.save_image(rendering, os.path.join(render_path, '{0:05d}'.format(idx) + \".png\"))\n",
    "#         torchvision.utils.save_image(gt, os.path.join(gts_path, '{0:05d}'.format(idx) + \".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2962ff04-1abe-4b0d-9d55-c966fa70a5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def render_sets(dataset : ModelParams, iteration : int, pipeline : PipelineParams, skip_train : bool, skip_test : bool):\n",
    "#     with torch.no_grad():\n",
    "#         gaussians = GaussianModel(dataset.sh_degree)\n",
    "#         scene = Scene(dataset, gaussians, load_iteration=iteration, shuffle=False)\n",
    "\n",
    "#         bg_color = [1,1,1] if dataset.white_background else [0, 0, 0]\n",
    "#         background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "#         if not skip_train:\n",
    "#              render_set(dataset.model_path, \"train\", scene.loaded_iter, scene.getTrainCameras(), gaussians, pipeline, background)\n",
    "\n",
    "#         if not skip_test:\n",
    "#              render_set(dataset.model_path, \"test\", scene.loaded_iter, scene.getTestCameras(), gaussians, pipeline, background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f5baf74-0665-4090-84ac-7aa81df87218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Set up command line argument parser\n",
    "#     parser = ArgumentParser(description=\"Testing script parameters\")\n",
    "#     model = ModelParams(parser, sentinel=True)\n",
    "#     pipeline = PipelineParams(parser)\n",
    "#     parser.add_argument(\"--iteration\", default=-1, type=int)\n",
    "#     parser.add_argument(\"--skip_train\", action=\"store_true\")\n",
    "#     parser.add_argument(\"--skip_test\", action=\"store_true\")\n",
    "#     parser.add_argument(\"--quiet\", action=\"store_true\")\n",
    "#     parser.add_argument(\"-f\", type=str, default = None)\n",
    "#     # parser.add_argument(\"--model_path\", type=str, default = \"headphone\")\n",
    "#     # parser.add_argument(\"--source_path\", type=str, default = \"/work/data/headphone/input\")     \n",
    "#     args = get_combined_args(parser)\n",
    "#     args.source_path = \"/work/data/headphone/\"\n",
    "#     args.model_path = \"/work/headphone/input.ply\"\n",
    "#     print(\"Rendering \" + args.model_path)\n",
    "\n",
    "#     # Initialize system state (RNG)\n",
    "#     safe_state(args.quiet)\n",
    "\n",
    "#     render_sets(model.extract(args), args.iteration, pipeline.extract(args), args.skip_train, args.skip_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00662bcc-4c1a-4344-b95b-dc05f2816914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
